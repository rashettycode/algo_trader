{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd7423bb-6866-4230-9e85-18e9ecbecbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6552756-a770-43e0-a386-096e0477282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tickers\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"NVDA\", \"AMZN\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "    \"V\", \"JNJ\", \"PG\", \"AVGO\", \"AMD\", \"ANET\", \"ODFL\", \"MNST\", \"DECK\", \"TSCO\", \"FICO\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8282e8-e06e-4126-b401-2df9dd45602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the data\n",
    "data_dir = 'data/raw'\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2113c093-1ed3-43f6-a568-b56b7a374eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch and save data\n",
    "def fetch_and_save_data(tickers, data_dir):\n",
    "    for ticker in tickers:\n",
    "        data = yf.download(ticker, start=\"2014-07-01\", end=\"2024-06-30\")\n",
    "        file_path = os.path.join(data_dir, f'{ticker}.parquet')\n",
    "        data.to_parquet(file_path)\n",
    "        print(f'Data for {ticker} saved to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33002544-fb93-447b-9185-9a1953c68473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "data_dir = 'data/raw'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "print(\"Directory created:\", os.path.exists(data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313aab53-eb89-4250-9f2e-3921a9c5543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low      Close  Adj Close     Volume\n",
      "Date                                                                        \n",
      "2014-07-01  23.379999  23.517500  23.282499  23.379999  20.680431  152892000\n",
      "2014-07-02  23.467501  23.514999  23.272499  23.370001  20.671593  113860000\n",
      "2014-07-03  23.417500  23.525000  23.299999  23.507500  20.793215   91567200\n",
      "2014-07-07  23.535000  23.997499  23.525000  23.992500  21.222212  225872000\n",
      "2014-07-08  24.067499  24.200001  23.480000  23.837500  21.085106  260888000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = yf.download(\"AAPL\", start=\"2014-07-01\", end=\"2024-06-30\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2039c18d-43fe-444b-9efa-8175e4bcc012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached pyarrow-16.1.0-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from pyarrow) (2.0.0)\n",
      "Using cached pyarrow-16.1.0-cp311-cp311-win_amd64.whl (25.9 MB)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-16.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190b1bb2-f2b3-4db1-8be5-7babea344d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for AAPL saved to data/raw\\AAPL.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for MSFT saved to data/raw\\MSFT.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for GOOGL saved to data/raw\\GOOGL.parquet\n",
      "Data for GOOG saved to data/raw\\GOOG.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for NVDA saved to data/raw\\NVDA.parquet\n",
      "Data for AMZN saved to data/raw\\AMZN.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for META saved to data/raw\\META.parquet\n",
      "Data for TSLA saved to data/raw\\TSLA.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for BRK-B saved to data/raw\\BRK-B.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for V saved to data/raw\\V.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for JNJ saved to data/raw\\JNJ.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for PG saved to data/raw\\PG.parquet\n",
      "Data for AVGO saved to data/raw\\AVGO.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for AMD saved to data/raw\\AMD.parquet\n",
      "Data for ANET saved to data/raw\\ANET.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for ODFL saved to data/raw\\ODFL.parquet\n",
      "Data for MNST saved to data/raw\\MNST.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for DECK saved to data/raw\\DECK.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for TSCO saved to data/raw\\TSCO.parquet\n",
      "Data for FICO saved to data/raw\\FICO.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"NVDA\", \"AMZN\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "    \"V\", \"JNJ\", \"PG\", \"AVGO\", \"AMD\", \"ANET\", \"ODFL\", \"MNST\", \"DECK\", \"TSCO\", \"FICO\"\n",
    "]\n",
    "\n",
    "# Directory to save the data\n",
    "data_dir = 'data/raw'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Function to fetch and save data\n",
    "def fetch_and_save_data(tickers, data_dir):\n",
    "    for ticker in tickers:\n",
    "        data = yf.download(ticker, start=\"2014-07-01\", end=\"2024-06-30\")\n",
    "        if not data.empty:\n",
    "            file_path = os.path.join(data_dir, f'{ticker}.parquet')\n",
    "            data.to_parquet(file_path)\n",
    "            print(f'Data for {ticker} saved to {file_path}')\n",
    "        else:\n",
    "            print(f'No data fetched for {ticker}')\n",
    "\n",
    "# Fetch and save the data\n",
    "fetch_and_save_data(tickers, data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac1a429a-46a9-465c-a276-cea7ade93746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the data\n",
    "data_dir = '../data/raw'\n",
    "os.makedirs(data_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c07915d-77e0-4ac4-a964-77757ceb97f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of ../data/raw: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List contents of the data/raw directory\n",
    "print(\"Contents of ../data/raw:\", os.listdir('../data/raw'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981673b1-df7f-4c03-ac50-d672294d462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for AAPL saved to ../data/raw\\AAPL.parquet\n",
      "Data for MSFT saved to ../data/raw\\MSFT.parquet\n",
      "Data for GOOGL saved to ../data/raw\\GOOGL.parquet\n",
      "Data for GOOG saved to ../data/raw\\GOOG.parquet\n",
      "Data for NVDA saved to ../data/raw\\NVDA.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for AMZN saved to ../data/raw\\AMZN.parquet\n",
      "Data for META saved to ../data/raw\\META.parquet\n",
      "Data for TSLA saved to ../data/raw\\TSLA.parquet\n",
      "Data for BRK-B saved to ../data/raw\\BRK-B.parquet\n",
      "Data for V saved to ../data/raw\\V.parquet\n",
      "Data for JNJ saved to ../data/raw\\JNJ.parquet\n",
      "Data for PG saved to ../data/raw\\PG.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for AVGO saved to ../data/raw\\AVGO.parquet\n",
      "Data for AMD saved to ../data/raw\\AMD.parquet\n",
      "Data for ANET saved to ../data/raw\\ANET.parquet\n",
      "Data for ODFL saved to ../data/raw\\ODFL.parquet\n",
      "Data for MNST saved to ../data/raw\\MNST.parquet\n",
      "Data for DECK saved to ../data/raw\\DECK.parquet\n",
      "Data for TSCO saved to ../data/raw\\TSCO.parquet\n",
      "Data for FICO saved to ../data/raw\\FICO.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"NVDA\", \"AMZN\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "    \"V\", \"JNJ\", \"PG\", \"AVGO\", \"AMD\", \"ANET\", \"ODFL\", \"MNST\", \"DECK\", \"TSCO\", \"FICO\"\n",
    "]\n",
    "\n",
    "# Directory to save the data\n",
    "data_dir = '../data/raw'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Function to fetch and save data\n",
    "def fetch_and_save_data(tickers, data_dir):\n",
    "    for ticker in tickers:\n",
    "        data = yf.download(ticker, start=\"2014-07-01\", end=\"2024-06-30\")\n",
    "        if not data.empty:\n",
    "            file_path = os.path.join(data_dir, f'{ticker}.parquet')\n",
    "            data.to_parquet(file_path)\n",
    "            print(f'Data for {ticker} saved to {file_path}')\n",
    "        else:\n",
    "            print(f'No data fetched for {ticker}')\n",
    "\n",
    "# Fetch and save the data\n",
    "fetch_and_save_data(tickers, data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04c122ea-38fd-4228-9688-4757819c171b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for SPY saved to ../data/extra\\SPY.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for ^DJI saved to ../data/extra\\^DJI.parquet\n",
      "Data for ^VIX saved to ../data/extra\\^VIX.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for GC=F saved to ../data/extra\\GC=F.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for CL=F saved to ../data/extra\\CL=F.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of additional tickers (SPY, DJI, VIX, Gold, Crude Oil)\n",
    "extra_tickers = [\"SPY\", \"^DJI\", \"^VIX\", \"GC=F\", \"CL=F\"]\n",
    "\n",
    "# Directory to save the extra data\n",
    "extra_data_dir = '../data/extra'\n",
    "os.makedirs(extra_data_dir, exist_ok=True)\n",
    "\n",
    "# Function to fetch and save data\n",
    "def fetch_and_save_data(tickers, data_dir):\n",
    "    for ticker in tickers:\n",
    "        data = yf.download(ticker, start=\"2014-07-01\", end=\"2024-06-30\")\n",
    "        if not data.empty:\n",
    "            file_path = os.path.join(data_dir, f'{ticker}.parquet')\n",
    "            data.to_parquet(file_path)\n",
    "            print(f'Data for {ticker} saved to {file_path}')\n",
    "        else:\n",
    "            print(f'No data fetched for {ticker}')\n",
    "\n",
    "# Fetch and save the additional tickers data\n",
    "fetch_and_save_data(extra_tickers, extra_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ac555-e0d9-44d0-aff0-d08ca797bea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
