{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f05664-d650-4a5e-96e2-2f581be71bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: textblob in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from pandas) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from nltk>=3.8->textblob) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae06896c-4b8e-4726-ba82-0fec6c8afb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of AAPL data:\n",
      "                 Open       High        Low      Close  Adj Close     Volume\n",
      "Date                                                                        \n",
      "2014-07-01  23.379999  23.517500  23.282499  23.379999  20.680428  152892000\n",
      "2014-07-02  23.467501  23.514999  23.272499  23.370001  20.671591  113860000\n",
      "2014-07-03  23.417500  23.525000  23.299999  23.507500  20.793215   91567200\n",
      "2014-07-07  23.535000  23.997499  23.525000  23.992500  21.222212  225872000\n",
      "2014-07-08  24.067499  24.200001  23.480000  23.837500  21.085104  260888000\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "\n",
      "Head of DJI data:\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "2014-07-01  16828.529297  16998.699219  16828.529297  16956.070312   \n",
      "2014-07-02  16949.710938  16986.630859  16949.710938  16976.240234   \n",
      "2014-07-03  16979.000000  17074.650391  16979.000000  17068.259766   \n",
      "2014-07-07  17063.830078  17063.830078  16992.449219  17024.210938   \n",
      "2014-07-08  17022.089844  17022.089844  16874.789062  16906.619141   \n",
      "\n",
      "               Adj Close    Volume  \n",
      "Date                                \n",
      "2014-07-01  16956.070312  74050000  \n",
      "2014-07-02  16976.240234  57840000  \n",
      "2014-07-03  17068.259766  66800000  \n",
      "2014-07-07  17024.210938  61480000  \n",
      "2014-07-08  16906.619141  75250000  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "\n",
      "Head of VIX data:\n",
      "             Open   High    Low  Close  Adj Close  Volume\n",
      "Date                                                     \n",
      "2014-07-01  11.28  11.42  10.92  11.15      11.15       0\n",
      "2014-07-02  11.18  11.18  10.56  10.82      10.82       0\n",
      "2014-07-03  10.47  10.76  10.28  10.32      10.32       0\n",
      "2014-07-07  11.15  11.54  11.01  11.33      11.33       0\n",
      "2014-07-08  11.72  12.51  11.72  11.98      11.98       0\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "\n",
      "Head of CL=F data:\n",
      "                  Open        High         Low       Close   Adj Close  Volume\n",
      "Date                                                                          \n",
      "2014-07-01  105.440002  106.089996  104.599998  105.339996  105.339996  221685\n",
      "2014-07-02  105.209999  105.529999  104.099998  104.480003  104.480003  240067\n",
      "2014-07-03  104.269997  104.290001  103.669998  104.059998  104.059998  169938\n",
      "2014-07-07  104.059998  104.129997  103.190002  103.529999  103.529999  189250\n",
      "2014-07-08  103.389999  104.199997  103.010002  103.400002  103.400002  249378\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "\n",
      "Head of GC=F data:\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2014-07-01  1326.699951  1331.400024  1326.199951  1326.400024  1326.400024   \n",
      "2014-07-02  1326.800049  1330.699951  1326.800049  1330.699951  1330.699951   \n",
      "2014-07-03  1327.300049  1327.699951  1313.000000  1320.400024  1320.400024   \n",
      "2014-07-07  1318.699951  1320.300049  1313.199951  1316.500000  1316.500000   \n",
      "2014-07-08  1318.400024  1323.500000  1316.000000  1316.000000  1316.000000   \n",
      "\n",
      "            Volume  \n",
      "Date                \n",
      "2014-07-01      51  \n",
      "2014-07-02     226  \n",
      "2014-07-03      40  \n",
      "2014-07-07      93  \n",
      "2014-07-08       6  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "\n",
      "Head of SPY data:\n",
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2014-07-01  196.199997  197.630005  196.130005  197.029999  164.916840   \n",
      "2014-07-02  197.050003  197.479996  196.960007  197.229996  165.084198   \n",
      "2014-07-03  197.789993  198.289993  197.639999  198.199997  165.896118   \n",
      "2014-07-07  197.820007  197.979996  197.220001  197.509995  165.318527   \n",
      "2014-07-08  197.149994  197.220001  195.759995  196.240005  164.255585   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2014-07-01   90470000  \n",
      "2014-07-02   52475000  \n",
      "2014-07-03   52938800  \n",
      "2014-07-07   61696000  \n",
      "2014-07-08  108143000  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of tickers and indices\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"NVDA\", \"AMZN\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "    \"V\", \"JNJ\", \"PG\", \"AVGO\", \"AMD\", \"ANET\", \"ODFL\", \"MNST\", \"DECK\", \"TSCO\", \"FICO\"\n",
    "]\n",
    "\n",
    "indices = {\n",
    "    \"DJI\": \"data/extra/^DJI.parquet\",\n",
    "    \"VIX\": \"data/extra/^VIX.parquet\",\n",
    "    \"CL=F\": \"data/extra/CL=F.parquet\",\n",
    "    \"GC=F\": \"data/extra/GC=F.parquet\",\n",
    "    \"SPY\": \"data/extra/SPY.parquet\"\n",
    "}\n",
    "\n",
    "# Directory paths\n",
    "raw_data_dir = 'data/raw'\n",
    "\n",
    "# Inspect the structure of one historical price data file\n",
    "def inspect_file(ticker, data_dir):\n",
    "    file_path = os.path.join(data_dir, f'{ticker}.parquet')\n",
    "    df = pd.read_parquet(file_path)\n",
    "    print(f\"\\nHead of {ticker} data:\")\n",
    "    print(df.head())\n",
    "    print(df.columns)\n",
    "\n",
    "# Inspect one historical price data file\n",
    "inspect_file('AAPL', raw_data_dir)\n",
    "\n",
    "# Inspect the structure of the extra index data files\n",
    "for index, file_path in indices.items():\n",
    "    print(f\"\\nHead of {index} data:\")\n",
    "    df = pd.read_parquet(file_path)\n",
    "    print(df.head())\n",
    "    print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8bd476e-a527-4165-9ca8-264d5a951581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of data/extra/^DJI.parquet data:\n",
      "                    Open          High           Low         Close  \\\n",
      "Date                                                                 \n",
      "2014-07-01  16828.529297  16998.699219  16828.529297  16956.070312   \n",
      "2014-07-02  16949.710938  16986.630859  16949.710938  16976.240234   \n",
      "2014-07-03  16979.000000  17074.650391  16979.000000  17068.259766   \n",
      "2014-07-07  17063.830078  17063.830078  16992.449219  17024.210938   \n",
      "2014-07-08  17022.089844  17022.089844  16874.789062  16906.619141   \n",
      "\n",
      "               Adj Close    Volume  \n",
      "Date                                \n",
      "2014-07-01  16956.070312  74050000  \n",
      "2014-07-02  16976.240234  57840000  \n",
      "2014-07-03  17068.259766  66800000  \n",
      "2014-07-07  17024.210938  61480000  \n",
      "2014-07-08  16906.619141  75250000  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "\n",
      "Head of data/extra/^VIX.parquet data:\n",
      "             Open   High    Low  Close  Adj Close  Volume\n",
      "Date                                                     \n",
      "2014-07-01  11.28  11.42  10.92  11.15      11.15       0\n",
      "2014-07-02  11.18  11.18  10.56  10.82      10.82       0\n",
      "2014-07-03  10.47  10.76  10.28  10.32      10.32       0\n",
      "2014-07-07  11.15  11.54  11.01  11.33      11.33       0\n",
      "2014-07-08  11.72  12.51  11.72  11.98      11.98       0\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "\n",
      "Head of data/extra/CL=F.parquet data:\n",
      "                  Open        High         Low       Close   Adj Close  Volume\n",
      "Date                                                                          \n",
      "2014-07-01  105.440002  106.089996  104.599998  105.339996  105.339996  221685\n",
      "2014-07-02  105.209999  105.529999  104.099998  104.480003  104.480003  240067\n",
      "2014-07-03  104.269997  104.290001  103.669998  104.059998  104.059998  169938\n",
      "2014-07-07  104.059998  104.129997  103.190002  103.529999  103.529999  189250\n",
      "2014-07-08  103.389999  104.199997  103.010002  103.400002  103.400002  249378\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "\n",
      "Head of data/extra/GC=F.parquet data:\n",
      "                   Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "2014-07-01  1326.699951  1331.400024  1326.199951  1326.400024  1326.400024   \n",
      "2014-07-02  1326.800049  1330.699951  1326.800049  1330.699951  1330.699951   \n",
      "2014-07-03  1327.300049  1327.699951  1313.000000  1320.400024  1320.400024   \n",
      "2014-07-07  1318.699951  1320.300049  1313.199951  1316.500000  1316.500000   \n",
      "2014-07-08  1318.400024  1323.500000  1316.000000  1316.000000  1316.000000   \n",
      "\n",
      "            Volume  \n",
      "Date                \n",
      "2014-07-01      51  \n",
      "2014-07-02     226  \n",
      "2014-07-03      40  \n",
      "2014-07-07      93  \n",
      "2014-07-08       6  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n",
      "\n",
      "Head of data/extra/SPY.parquet data:\n",
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2014-07-01  196.199997  197.630005  196.130005  197.029999  164.916840   \n",
      "2014-07-02  197.050003  197.479996  196.960007  197.229996  165.084198   \n",
      "2014-07-03  197.789993  198.289993  197.639999  198.199997  165.896118   \n",
      "2014-07-07  197.820007  197.979996  197.220001  197.509995  165.318527   \n",
      "2014-07-08  197.149994  197.220001  195.759995  196.240005  164.255585   \n",
      "\n",
      "               Volume  \n",
      "Date                   \n",
      "2014-07-01   90470000  \n",
      "2014-07-02   52475000  \n",
      "2014-07-03   52938800  \n",
      "2014-07-07   61696000  \n",
      "2014-07-08  108143000  \n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Key indices and their corresponding filenames\n",
    "indices = {\n",
    "    \"DJI\": \"data/extra/^DJI.parquet\",\n",
    "    \"VIX\": \"data/extra/^VIX.parquet\",\n",
    "    \"CL=F\": \"data/extra/CL=F.parquet\",\n",
    "    \"GC=F\": \"data/extra/GC=F.parquet\",\n",
    "    \"SPY\": \"data/extra/SPY.parquet\"\n",
    "}\n",
    "\n",
    "# Function to inspect the structure of the Parquet files\n",
    "def inspect_file(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    print(f\"\\nHead of {file_path} data:\")\n",
    "    print(df.head())\n",
    "    print(df.columns)\n",
    "\n",
    "# Inspect the structure of the extra index data files\n",
    "for index, file_path in indices.items():\n",
    "    inspect_file(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724265f2-9061-4a3a-afef-e51fc785c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of AAPL news data:\n",
      "{'source': {'id': None, 'name': \"Investor's Business Daily\"}, 'author': \"Investor's Business Daily\", 'title': \"As Nvidia, Apple Grab Headlines, This Mag 7 Lays Down AI 'Bedrock'\", 'description': 'While laying an AI foundation with Amazon Bedrock, Amazon sets up new buy point.', 'url': 'https://www.investors.com/research/ibd-stock-analysis/amazon-stock-ai-bedrock-aws/', 'urlToImage': 'https://www.investors.com/wp-content/uploads/2024/06/Stock-earthlayersrock-generatedai-01-adobe.jpg', 'publishedAt': '2024-06-20T13:52:07Z', 'content': 'Much of the buzz around Magnificent Seven stocks like Nvidia (NVDA), Microsoft (MSFT), Apple (AAPL), Alphabet (GOOGL) and Meta Platforms (META) stems from the boom in artificial intelligence. Meanwhi… [+2708 chars]'}\n",
      "{'source': {'id': None, 'name': 'MarketWatch'}, 'author': 'Joseph Adinolfi', 'title': 'Popular tech ETF forced to dump Apple stock, buy Nvidia in upcoming rebalancing', 'description': 'Nvidia will take the No. 2 spot in the Technology Select Sector SPDR ETF following a close race', 'url': 'https://www.marketwatch.com/story/popular-tech-etf-forced-to-dump-apple-stock-buy-nvidia-in-upcoming-rebalancing-00bcd294', 'urlToImage': 'https://images.mktw.net/im-52690823/social', 'publishedAt': '2024-06-17T17:49:00Z', 'content': 'A major shakeup is coming to a popular exchange-traded fund that tracks technology stocks. Following Fridays race-to-the-finish close, State Street Global Advisors has confirmed that Microsoft Corp. … [+2514 chars]'}\n",
      "{'source': {'id': None, 'name': 'R-bloggers.com'}, 'author': 'Dario Radečić', 'title': 'R Dygraphs: How To Visualize Time Series Data In R And R Shiny', 'description': 'When it comes to finding an R package capable of making interactive visualizations out of the box while also working flawlessly with R Shiny, you don’t have that many options. Sure, there’s Highcarts, but what if you’re looking for something more specialized …', 'url': 'https://www.r-bloggers.com/2024/07/r-dygraphs-how-to-visualize-time-series-data-in-r-and-r-shiny/', 'urlToImage': 'https://wordpress.appsilon.com/wp-content/uploads/2024/07/667aab86bfa6f596042e43fa_R-ggvis-How-to-make-interactive-data-visualizations-in-r-and-shiny-1-p-800.webp', 'publishedAt': '2024-07-02T07:00:03Z', 'content': 'When it comes to finding an R package capable of making interactive visualizations out of the box while also working flawlessly with R Shiny, you dont have that many options. Sure, theres Highcarts, … [+12598 chars]'}\n",
      "{'source': {'id': None, 'name': 'Biztoc.com'}, 'author': '247wallst.com', 'title': 'Apple’s Multibillion Dollar Microsoft Heist Actually Worked', 'description': 'Apple (NASDAQ: AAPL) recently announced Apple Intelligence, pushing its shares up roughly 10% over a few days and briefly surpassing Microsoft (NASDAQ: MSFT) as the most valuable company on earth. This surge is attributed to the AI-driven excitement, similar …', 'url': 'https://biztoc.com/x/f52203bdf17e7644', 'urlToImage': 'https://biztoc.com/cdn/f52203bdf17e7644_s.webp', 'publishedAt': '2024-06-24T00:23:14Z', 'content': 'Apple (NASDAQ: AAPL) recently announced Apple Intelligence, pushing its shares up roughly 10% over a few days and briefly surpassing Microsoft (NASDAQ: MSFT) as the most valuable company on earth. Th… [+137 chars]'}\n",
      "{'source': {'id': None, 'name': 'Biztoc.com'}, 'author': 'benzinga.com', 'title': 'Amazon Stock Trades At New 52-Week High: Book Profits Or More Upside Ahead? - Amazon.com (NASDAQ:AMZN)', 'description': 'Amazon.com Inc AMZN stock just hit a dazzling new milestone, crossing the $2 trillion market cap for the first time ever on Wednesday.\\nThe stock has now joined the elite ranks of Microsoft Corp MSFT, Apple Inc AAPL, Nvidia Corp NVDA and Alphabet Inc GOOG GOOG…', 'url': 'https://biztoc.com/x/2ae50dea493576e9', 'urlToImage': 'https://biztoc.com/cdn/2ae50dea493576e9_s.webp', 'publishedAt': '2024-06-28T15:17:46Z', 'content': 'Amazon.com Inc AMZN stock just hit a dazzling new milestone, crossing the $2 trillion market cap for the first time ever on Wednesday.The stock has now joined the elite ranks of Microsoft Corp MSFT, … [+136 chars]'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Directory for news data\n",
    "news_data_dir = 'data/news'\n",
    "\n",
    "# Function to load and inspect the news data from a file\n",
    "def inspect_news_file(ticker):\n",
    "    file_path = os.path.join(news_data_dir, f'{ticker}_key_news.json')\n",
    "    with open(file_path, 'r') as file:\n",
    "        news_data = json.load(file)\n",
    "        print(f\"\\nHead of {ticker} news data:\")\n",
    "        for article in news_data[:5]:  # Display the first 5 articles\n",
    "            print(article)\n",
    "\n",
    "# Inspect news data for a specific ticker\n",
    "inspect_news_file('AAPL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a75d78-ae9d-4f28-9d5b-5d8495fc5f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Ticker       Open       High        Low      Close     Volume  \\\n",
      "0  2014-07-01   AAPL  23.379999  23.517500  23.282499  23.379999  152892000   \n",
      "1  2014-07-02   AAPL  23.467501  23.514999  23.272499  23.370001  113860000   \n",
      "2  2014-07-03   AAPL  23.417500  23.525000  23.299999  23.507500   91567200   \n",
      "3  2014-07-07   AAPL  23.535000  23.997499  23.525000  23.992500  225872000   \n",
      "4  2014-07-08   AAPL  24.067499  24.200001  23.480000  23.837500  260888000   \n",
      "\n",
      "   Sentiment     DJI_Close  VIX_Close  CL=F_Close   GC=F_Close   SPY_Close  \n",
      "0        NaN  16956.070312      11.15  105.339996  1326.400024  197.029999  \n",
      "1        NaN  16976.240234      10.82  104.480003  1330.699951  197.229996  \n",
      "2        NaN  17068.259766      10.32  104.059998  1320.400024  198.199997  \n",
      "3        NaN  17024.210938      11.33  103.529999  1316.500000  197.509995  \n",
      "4        NaN  16906.619141      11.98  103.400002  1316.000000  196.240005  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"NVDA\", \"AMZN\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "    \"V\", \"JNJ\", \"PG\", \"AVGO\", \"AMD\", \"ANET\", \"ODFL\", \"MNST\", \"DECK\", \"TSCO\", \"FICO\"\n",
    "]\n",
    "\n",
    "# Key indices and their corresponding filenames\n",
    "indices = {\n",
    "    \"DJI\": \"data/extra/^DJI.parquet\",\n",
    "    \"VIX\": \"data/extra/^VIX.parquet\",\n",
    "    \"CL=F\": \"data/extra/CL=F.parquet\",\n",
    "    \"GC=F\": \"data/extra/GC=F.parquet\",\n",
    "    \"SPY\": \"data/extra/SPY.parquet\"\n",
    "}\n",
    "\n",
    "# Directory paths\n",
    "raw_data_dir = 'data/raw'\n",
    "news_data_dir = 'data/news'\n",
    "processed_data_dir = 'data/processed'\n",
    "\n",
    "# Create the processed data directory if it doesn't exist\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "\n",
    "# Function to load news data from a file\n",
    "def load_news_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Function to perform sentiment analysis on news articles\n",
    "def analyze_sentiment(article):\n",
    "    title = article.get('title', '')\n",
    "    description = article.get('description', '')\n",
    "    text = str(title) + ' ' + str(description)\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "# Function to load historical data from Parquet files\n",
    "def load_historical_data(ticker, data_dir):\n",
    "    file_path = os.path.join(data_dir, f'{ticker}.parquet')\n",
    "    data = pd.read_parquet(file_path)\n",
    "    data.reset_index(inplace=True)\n",
    "    data['Date'] = pd.to_datetime(data['Date']).dt.date\n",
    "    data['Ticker'] = ticker\n",
    "    return data\n",
    "\n",
    "# Function to load index data from the provided Parquet file\n",
    "def load_index_data(file_path):\n",
    "    data = pd.read_parquet(file_path)\n",
    "    data.reset_index(inplace=True)\n",
    "    data['Date'] = pd.to_datetime(data['Date']).dt.date\n",
    "    return data\n",
    "\n",
    "# Create an empty DataFrame to store the combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Fetch and combine data for each ticker\n",
    "for ticker in tickers:\n",
    "    # Load historical data\n",
    "    historical_data = load_historical_data(ticker, raw_data_dir)\n",
    "\n",
    "    # Load and analyze sentiment data\n",
    "    file_path = os.path.join(news_data_dir, f'{ticker}_key_news.json')\n",
    "    news_data = load_news_data(file_path)\n",
    "    if news_data:\n",
    "        sentiments = [analyze_sentiment(article) for article in news_data]\n",
    "        sentiment_dates = [datetime.strptime(article['publishedAt'], '%Y-%m-%dT%H:%M:%SZ').date() for article in news_data]\n",
    "        sentiment_df = pd.DataFrame({'Date': sentiment_dates, 'Sentiment': sentiments})\n",
    "        \n",
    "        # Merge historical data with sentiment data\n",
    "        merged_data = pd.merge(historical_data, sentiment_df, on='Date', how='left')\n",
    "    else:\n",
    "        historical_data['Sentiment'] = None\n",
    "        merged_data = historical_data\n",
    "\n",
    "    # Append to the combined dataset\n",
    "    combined_data = pd.concat([combined_data, merged_data], ignore_index=True)\n",
    "\n",
    "# Load key indices data and merge with the combined dataset\n",
    "for index, file_path in indices.items():\n",
    "    index_data = load_index_data(file_path)\n",
    "    index_data = index_data[['Date', 'Close']]\n",
    "    index_data.rename(columns={'Close': f'{index}_Close'}, inplace=True)\n",
    "    combined_data = pd.merge(combined_data, index_data, on='Date', how='left')\n",
    "\n",
    "# Streamline the dataset by keeping necessary columns\n",
    "columns_to_keep = ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume', 'Sentiment'] + [f'{index}_Close' for index in indices.keys()]\n",
    "streamlined_data = combined_data[columns_to_keep]\n",
    "\n",
    "# Save the streamlined dataset to a Parquet file in the processed data directory\n",
    "save_path = os.path.join(processed_data_dir, 'streamlined_dataset.parquet')\n",
    "streamlined_data.to_parquet(save_path, index=False)\n",
    "\n",
    "# Display the first few rows of the streamlined dataset\n",
    "print(streamlined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7518f24-4845-4953-b5d2-14b9a1dcee52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Ticker       Open       High        Low      Close     Volume  \\\n",
      "0  2014-07-01   AAPL  23.379999  23.517500  23.282499  23.379999  152892000   \n",
      "1  2014-07-02   AAPL  23.467501  23.514999  23.272499  23.370001  113860000   \n",
      "2  2014-07-03   AAPL  23.417500  23.525000  23.299999  23.507500   91567200   \n",
      "3  2014-07-07   AAPL  23.535000  23.997499  23.525000  23.992500  225872000   \n",
      "4  2014-07-08   AAPL  24.067499  24.200001  23.480000  23.837500  260888000   \n",
      "\n",
      "   Sentiment     DJI_Close  VIX_Close  CL=F_Close   GC=F_Close   SPY_Close  \n",
      "0        NaN  16956.070312      11.15  105.339996  1326.400024  197.029999  \n",
      "1        NaN  16976.240234      10.82  104.480003  1330.699951  197.229996  \n",
      "2        NaN  17068.259766      10.32  104.059998  1320.400024  198.199997  \n",
      "3        NaN  17024.210938      11.33  103.529999  1316.500000  197.509995  \n",
      "4        NaN  16906.619141      11.98  103.400002  1316.000000  196.240005  \n",
      "               Open          High           Low         Close        Volume  \\\n",
      "count  50886.000000  50886.000000  50886.000000  50886.000000  5.088600e+04   \n",
      "mean     125.135817    126.620253    123.665076    125.193370  5.154814e+07   \n",
      "std      135.545350    137.306727    133.932581    135.702017  1.198318e+08   \n",
      "min        0.423250      0.432500      0.419250      0.419750  0.000000e+00   \n",
      "25%       40.835500     41.322249     40.377625     40.894126  3.053325e+06   \n",
      "50%       91.209999     92.129997     90.292000     91.180000  1.271985e+07   \n",
      "75%      163.039993    164.796627    161.282997    162.951874  4.479644e+07   \n",
      "max     1480.290039   1518.270020   1480.290039   1488.660034  3.692928e+09   \n",
      "\n",
      "        Sentiment     DJI_Close     VIX_Close    CL=F_Close    GC=F_Close  \\\n",
      "count  748.000000  50886.000000  50886.000000  50846.000000  50826.000000   \n",
      "mean     0.106731  26574.058386     18.070452     62.837708   1544.588807   \n",
      "std      0.185721   6940.484017      7.288201     18.945331    337.937038   \n",
      "min     -0.800000  15660.179688      9.140000    -37.630001   1050.800049   \n",
      "25%      0.000000  19884.910156     13.140000     48.660000   1249.800049   \n",
      "50%      0.083333  26048.509766     16.040001     59.959999   1420.900024   \n",
      "75%      0.202500  33348.601562     21.230000     76.339996   1834.099976   \n",
      "max      0.800000  40003.589844     82.690002    123.699997   2433.899902   \n",
      "\n",
      "          SPY_Close  \n",
      "count  50886.000000  \n",
      "mean     318.677894  \n",
      "std       99.193707  \n",
      "min      182.860001  \n",
      "25%      226.460007  \n",
      "50%      289.779999  \n",
      "75%      410.279999  \n",
      "max      548.489990  \n",
      "Date              0\n",
      "Ticker            0\n",
      "Open              0\n",
      "High              0\n",
      "Low               0\n",
      "Close             0\n",
      "Volume            0\n",
      "Sentiment     50138\n",
      "DJI_Close         0\n",
      "VIX_Close         0\n",
      "CL=F_Close       40\n",
      "GC=F_Close       60\n",
      "SPY_Close         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the streamlined dataset\n",
    "streamlined_data_path = 'data/processed/streamlined_dataset.parquet'\n",
    "streamlined_data = pd.read_parquet(streamlined_data_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(streamlined_data.head())\n",
    "\n",
    "# Display summary statistics\n",
    "print(streamlined_data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(streamlined_data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "141553e7-d308-42be-87a0-43339086ca21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date          0\n",
      "Ticker        0\n",
      "Open          0\n",
      "High          0\n",
      "Low           0\n",
      "Close         0\n",
      "Volume        0\n",
      "Sentiment     0\n",
      "DJI_Close     0\n",
      "VIX_Close     0\n",
      "CL=F_Close    0\n",
      "GC=F_Close    0\n",
      "SPY_Close     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the data to avoid chained assignment warnings\n",
    "streamlined_data_copy = streamlined_data.copy()\n",
    "\n",
    "# Fill missing sentiment values with 0\n",
    "streamlined_data_copy['Sentiment'] = streamlined_data_copy['Sentiment'].fillna(0)\n",
    "\n",
    "# Forward fill missing values for CL=F_Close and GC=F_Close using .ffill() method\n",
    "streamlined_data_copy['CL=F_Close'] = streamlined_data_copy['CL=F_Close'].ffill()\n",
    "streamlined_data_copy['GC=F_Close'] = streamlined_data_copy['GC=F_Close'].ffill()\n",
    "\n",
    "# Check for remaining missing values\n",
    "print(streamlined_data_copy.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2f2b5-b578-4a42-8899-17c97a8d0293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
