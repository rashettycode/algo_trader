{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f53bfe-7a3e-4534-b1d1-c3da93bdc238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul\\desktop\\project_algo\\env\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bea19-fede-468a-834b-7c90b7e751ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048ddf17-362c-42a7-a0e1-ee136cb03644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data to save for AAPL\n",
      "No data to save for MSFT\n",
      "No data to save for GOOGL\n",
      "No data to save for GOOG\n",
      "No data to save for NVDA\n",
      "No data to save for AMZN\n",
      "No data to save for META\n",
      "No data to save for TSLA\n",
      "No data to save for BRK-B\n",
      "Key news data for V saved to ../data/news\\V_key_news.json\n",
      "No data to save for JNJ\n",
      "No data to save for PG\n",
      "Key news data for AVGO saved to ../data/news\\AVGO_key_news.json\n",
      "No data to save for AMD\n",
      "No data to save for ANET\n",
      "No data to save for ODFL\n",
      "Key news data for MNST saved to ../data/news\\MNST_key_news.json\n",
      "Key news data for DECK saved to ../data/news\\DECK_key_news.json\n",
      "Key news data for TSCO saved to ../data/news\\TSCO_key_news.json\n",
      "Key news data for FICO saved to ../data/news\\FICO_key_news.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Replace with your own API key\n",
    "API_KEY = '2UIXF3NSIUG2K9MF'\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"NVDA\", \"AMZN\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "    \"V\", \"JNJ\", \"PG\", \"AVGO\", \"AMD\", \"ANET\", \"ODFL\", \"MNST\", \"DECK\", \"TSCO\", \"FICO\"\n",
    "]\n",
    "\n",
    "# Directory to save the news data\n",
    "news_data_dir = '../data/news'\n",
    "os.makedirs(news_data_dir, exist_ok=True)\n",
    "\n",
    "def fetch_news_data(ticker, api_key):\n",
    "    url = f\"https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={ticker}&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch news for {ticker}\")\n",
    "        return None\n",
    "\n",
    "def filter_key_news(news_data):\n",
    "    key_news = []\n",
    "    if news_data and 'feed' in news_data:\n",
    "        for article in news_data['feed']:\n",
    "            if article['time_published'] > '2023-01-01T00:00:00' and article['overall_sentiment_score'] >= 0.5:\n",
    "                key_news.append(article)\n",
    "    return key_news\n",
    "\n",
    "def save_news_data(ticker, data, data_dir):\n",
    "    if data:\n",
    "        file_path = os.path.join(data_dir, f'{ticker}_key_news.json')\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "        print(f'Key news data for {ticker} saved to {file_path}')\n",
    "    else:\n",
    "        print(f'No data to save for {ticker}')\n",
    "\n",
    "# Fetch and save key news data for each ticker\n",
    "for ticker in tickers:\n",
    "    news_data = fetch_news_data(ticker, API_KEY)\n",
    "    key_news = filter_key_news(news_data)\n",
    "    save_news_data(ticker, key_news, news_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf271843-a053-4a14-b7b7-76ff2f03e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for AAPL: Status code 200\n",
      "Key news data for AAPL saved to ../data/news\\AAPL_key_news.json\n",
      "Fetching news for MSFT: Status code 200\n",
      "Key news data for MSFT saved to ../data/news\\MSFT_key_news.json\n",
      "Fetching news for GOOGL: Status code 200\n",
      "Key news data for GOOGL saved to ../data/news\\GOOGL_key_news.json\n",
      "Fetching news for GOOG: Status code 200\n",
      "Key news data for GOOG saved to ../data/news\\GOOG_key_news.json\n",
      "Fetching news for NVDA: Status code 200\n",
      "Key news data for NVDA saved to ../data/news\\NVDA_key_news.json\n",
      "Fetching news for AMZN: Status code 200\n",
      "Key news data for AMZN saved to ../data/news\\AMZN_key_news.json\n",
      "Fetching news for META: Status code 200\n",
      "Key news data for META saved to ../data/news\\META_key_news.json\n",
      "Fetching news for TSLA: Status code 200\n",
      "Key news data for TSLA saved to ../data/news\\TSLA_key_news.json\n",
      "Fetching news for BRK-B: Status code 200\n",
      "Key news data for BRK-B saved to ../data/news\\BRK-B_key_news.json\n",
      "Fetching news for V: Status code 200\n",
      "Key news data for V saved to ../data/news\\V_key_news.json\n",
      "Fetching news for JNJ: Status code 200\n",
      "Key news data for JNJ saved to ../data/news\\JNJ_key_news.json\n",
      "Fetching news for PG: Status code 200\n",
      "Key news data for PG saved to ../data/news\\PG_key_news.json\n",
      "Fetching news for AVGO: Status code 200\n",
      "Key news data for AVGO saved to ../data/news\\AVGO_key_news.json\n",
      "Fetching news for AMD: Status code 200\n",
      "Key news data for AMD saved to ../data/news\\AMD_key_news.json\n",
      "Fetching news for ANET: Status code 200\n",
      "Key news data for ANET saved to ../data/news\\ANET_key_news.json\n",
      "Fetching news for ODFL: Status code 200\n",
      "Key news data for ODFL saved to ../data/news\\ODFL_key_news.json\n",
      "Fetching news for MNST: Status code 200\n",
      "Key news data for MNST saved to ../data/news\\MNST_key_news.json\n",
      "Fetching news for DECK: Status code 200\n",
      "Key news data for DECK saved to ../data/news\\DECK_key_news.json\n",
      "Fetching news for TSCO: Status code 200\n",
      "Key news data for TSCO saved to ../data/news\\TSCO_key_news.json\n",
      "Fetching news for FICO: Status code 200\n",
      "Key news data for FICO saved to ../data/news\\FICO_key_news.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Replace with your own API key\n",
    "API_KEY = 'fb1b6755c1a34f3785531e582ef7313e'\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"NVDA\", \"AMZN\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "    \"V\", \"JNJ\", \"PG\", \"AVGO\", \"AMD\", \"ANET\", \"ODFL\", \"MNST\", \"DECK\", \"TSCO\", \"FICO\"\n",
    "]\n",
    "\n",
    "# Directory to save the news data\n",
    "news_data_dir = '../data/news'\n",
    "os.makedirs(news_data_dir, exist_ok=True)\n",
    "\n",
    "# Set the date range for the last 20 days\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=20)\n",
    "\n",
    "def fetch_news_data(ticker, api_key, start_date, end_date):\n",
    "    url = f\"https://newsapi.org/v2/everything?q={ticker}&from={start_date.strftime('%Y-%m-%d')}&to={end_date.strftime('%Y-%m-%d')}&sortBy=relevancy&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    print(f\"Fetching news for {ticker}: Status code {response.status_code}\")  # Debugging line\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch news for {ticker}. Response: {response.text}\")  # Debugging line\n",
    "        return None\n",
    "\n",
    "def filter_key_news(news_data):\n",
    "    key_news = []\n",
    "    if news_data and 'articles' in news_data:\n",
    "        for article in news_data['articles']:\n",
    "            key_news.append(article)\n",
    "    return key_news\n",
    "\n",
    "def save_news_data(ticker, data, data_dir):\n",
    "    if data:\n",
    "        file_path = os.path.join(data_dir, f'{ticker}_key_news.json')\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "        print(f'Key news data for {ticker} saved to {file_path}')\n",
    "    else:\n",
    "        print(f'No data to save for {ticker}')\n",
    "\n",
    "# Fetch and save key news data for each ticker\n",
    "for ticker in tickers:\n",
    "    news_data = fetch_news_data(ticker, API_KEY, start_date, end_date)\n",
    "    key_news = filter_key_news(news_data)\n",
    "    save_news_data(ticker, key_news, news_data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd18fd6f-6389-497c-a5f1-858cd2ad26a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of ../data/news: ['AAPL_key_news.json', 'AMD_key_news.json', 'AMZN_key_news.json', 'ANET_key_news.json', 'AVGO_key_news.json', 'BRK-B_key_news.json', 'DECK_key_news.json', 'FICO_key_news.json', 'GOOGL_key_news.json', 'GOOG_key_news.json', 'JNJ_key_news.json', 'META_key_news.json', 'MNST_key_news.json', 'MSFT_key_news.json', 'NVDA_key_news.json', 'ODFL_key_news.json', 'PG_key_news.json', 'TSCO_key_news.json', 'TSLA_key_news.json', 'V_key_news.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List contents of the data/news directory\n",
    "print(\"Contents of ../data/news:\", os.listdir('../data/news'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4199bab0-b2d9-4ccb-8772-cef68e939a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of ../data/news: ['AAPL_key_news.json', 'AMD_key_news.json', 'AMZN_key_news.json', 'ANET_key_news.json', 'AVGO_key_news.json', 'BRK-B_key_news.json', 'DECK_key_news.json', 'FICO_key_news.json', 'GOOGL_key_news.json', 'GOOG_key_news.json', 'JNJ_key_news.json', 'META_key_news.json', 'MNST_key_news.json', 'MSFT_key_news.json', 'NVDA_key_news.json', 'ODFL_key_news.json', 'PG_key_news.json', 'TSCO_key_news.json', 'TSLA_key_news.json', 'V_key_news.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory to check for saved news files\n",
    "news_data_dir = '../data/news'\n",
    "\n",
    "# List contents of the data/news directory\n",
    "print(\"Contents of ../data/news:\", os.listdir(news_data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43a40e27-b6fd-4c4a-aec7-6770f96e0156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news for AAPL: Status code 200\n",
      "Key news data for AAPL saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\AAPL_key_news.json\n",
      "Fetching news for MSFT: Status code 200\n",
      "Key news data for MSFT saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\MSFT_key_news.json\n",
      "Fetching news for GOOGL: Status code 200\n",
      "Key news data for GOOGL saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\GOOGL_key_news.json\n",
      "Fetching news for GOOG: Status code 200\n",
      "Key news data for GOOG saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\GOOG_key_news.json\n",
      "Fetching news for NVDA: Status code 200\n",
      "Key news data for NVDA saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\NVDA_key_news.json\n",
      "Fetching news for AMZN: Status code 200\n",
      "Key news data for AMZN saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\AMZN_key_news.json\n",
      "Fetching news for META: Status code 200\n",
      "Key news data for META saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\META_key_news.json\n",
      "Fetching news for TSLA: Status code 200\n",
      "Key news data for TSLA saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\TSLA_key_news.json\n",
      "Fetching news for BRK-B: Status code 200\n",
      "Key news data for BRK-B saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\BRK-B_key_news.json\n",
      "Fetching news for V: Status code 200\n",
      "Key news data for V saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\V_key_news.json\n",
      "Fetching news for JNJ: Status code 200\n",
      "Key news data for JNJ saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\JNJ_key_news.json\n",
      "Fetching news for PG: Status code 200\n",
      "Key news data for PG saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\PG_key_news.json\n",
      "Fetching news for AVGO: Status code 200\n",
      "Key news data for AVGO saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\AVGO_key_news.json\n",
      "Fetching news for AMD: Status code 200\n",
      "Key news data for AMD saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\AMD_key_news.json\n",
      "Fetching news for ANET: Status code 200\n",
      "Key news data for ANET saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\ANET_key_news.json\n",
      "Fetching news for ODFL: Status code 200\n",
      "Key news data for ODFL saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\ODFL_key_news.json\n",
      "Fetching news for MNST: Status code 200\n",
      "Key news data for MNST saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\MNST_key_news.json\n",
      "Fetching news for DECK: Status code 200\n",
      "Key news data for DECK saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\DECK_key_news.json\n",
      "Fetching news for TSCO: Status code 200\n",
      "Key news data for TSCO saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\TSCO_key_news.json\n",
      "Fetching news for FICO: Status code 200\n",
      "Key news data for FICO saved to C:\\Users\\rahul\\Desktop\\Project_Algo\\data\\news\\FICO_key_news.json\n",
      "Contents of data/news: ['AAPL_key_news.json', 'AMD_key_news.json', 'AMZN_key_news.json', 'ANET_key_news.json', 'AVGO_key_news.json', 'BRK-B_key_news.json', 'DECK_key_news.json', 'FICO_key_news.json', 'GOOGL_key_news.json', 'GOOG_key_news.json', 'JNJ_key_news.json', 'META_key_news.json', 'MNST_key_news.json', 'MSFT_key_news.json', 'NVDA_key_news.json', 'ODFL_key_news.json', 'PG_key_news.json', 'TSCO_key_news.json', 'TSLA_key_news.json', 'V_key_news.json']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Replace with your own API key\n",
    "API_KEY = 'fb1b6755c1a34f3785531e582ef7313e'\n",
    "\n",
    "# List of tickers\n",
    "tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"NVDA\", \"AMZN\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "    \"V\", \"JNJ\", \"PG\", \"AVGO\", \"AMD\", \"ANET\", \"ODFL\", \"MNST\", \"DECK\", \"TSCO\", \"FICO\"\n",
    "]\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Directory to save the news data\n",
    "news_data_dir = os.path.join(current_dir, 'data', 'news')\n",
    "os.makedirs(news_data_dir, exist_ok=True)\n",
    "\n",
    "# Set the date range for the last 30 days\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "def fetch_news_data(ticker, api_key, start_date, end_date):\n",
    "    url = f\"https://newsapi.org/v2/everything?q={ticker}&from={start_date.strftime('%Y-%m-%d')}&to={end_date.strftime('%Y-%m-%d')}&sortBy=relevancy&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    print(f\"Fetching news for {ticker}: Status code {response.status_code}\")  # Debugging line\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch news for {ticker}. Response: {response.text}\")  # Debugging line\n",
    "        return None\n",
    "\n",
    "def filter_key_news(news_data):\n",
    "    key_news = []\n",
    "    if news_data and 'articles' in news_data:\n",
    "        for article in news_data['articles']:\n",
    "            key_news.append(article)\n",
    "    return key_news\n",
    "\n",
    "def save_news_data(ticker, data, data_dir):\n",
    "    if data:\n",
    "        file_path = os.path.join(data_dir, f'{ticker}_key_news.json')\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "        print(f'Key news data for {ticker} saved to {file_path}')\n",
    "    else:\n",
    "        print(f'No data to save for {ticker}')\n",
    "\n",
    "# Fetch and save key news data for each ticker\n",
    "for ticker in tickers:\n",
    "    news_data = fetch_news_data(ticker, API_KEY, start_date, end_date)\n",
    "    key_news = filter_key_news(news_data)\n",
    "    save_news_data(ticker, key_news, news_data_dir)\n",
    "\n",
    "# Verify the contents of the news directory\n",
    "print(\"Contents of data/news:\", os.listdir(news_data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f288a567-475f-49b6-84eb-7f0a86be31f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
